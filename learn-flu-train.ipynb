{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries: Inspect and Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries required\n",
    "\n",
    "# Data Processing and EDA\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For bioinformatics tasks\n",
    "from Bio import SeqIO\n",
    "# older alignment method\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "# newer alignment method - not using this, \n",
    "# but just don't want to forget this option\n",
    "from Bio import Align\n",
    "from Bio.Align import PairwiseAligner\n",
    "import multiprocessing\n",
    "\n",
    "# For Machine Learning\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from seaborn import heatmap\n",
    "from sklearn.inspection import partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "# Show all the output for every print not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# Configuration and settings\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# To check if in Google Colab\n",
    "from IPython.core.getipython import get_ipython\n",
    "# To display all the output in a nicer table\n",
    "from IPython.display import display\n",
    "# To time the execution of the code\n",
    "import time\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if 'google.colab' in str(get_ipython()):\n",
    "    # TODO: if running on Google Colab, install any packages you need to here. For example:\n",
    "    #!pip install unidecode\n",
    "    #!pip install category_encoders\n",
    "    #!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's minimize randomness\n",
    "# numpy\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # For saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the FASTA file\n",
    "records = list(SeqIO.parse(\"/home/ajvilleg/Netdrive/AI/GISAID/EpiFlu_Training/28-Jul-2024/gisaid_epiflu_sequence_28-Jul-2024_USA.fasta\", \"fasta\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate_headers(records):\n",
    "    \"\"\"Checks for duplicate FASTA headers in a list of SeqIO records.\n",
    "\n",
    "    Args:\n",
    "        records: A list of SeqRecord objects.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of indices corresponding to duplicate records.\n",
    "        list: A list of duplicate headers.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    duplicates = []\n",
    "    duplicate_headers = []\n",
    "    for i, record in enumerate(records):\n",
    "        header = record.description  # Or use record.id\n",
    "        if header in seen:\n",
    "            duplicates.append(i)\n",
    "            duplicate_headers.append(header)\n",
    "        else:\n",
    "            seen.add(header)\n",
    "    return duplicates, duplicate_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates before extracting details\n",
    "duplicate_indices, duplicate_headers = check_duplicate_headers(records)\n",
    "if duplicate_indices:\n",
    "    print(\"Warning: Found the following duplicate FASTA headers:\")\n",
    "    for header in duplicate_headers:\n",
    "        print(header)\n",
    "    print(\"One copy of each duplicate record will be kept.\")\n",
    "\n",
    "    # Create a set of unique indices to keep\n",
    "    indices_to_keep = set(range(len(records))) - set(duplicate_indices)\n",
    "\n",
    "    # Filter the records list\n",
    "    records = [record for i, record in enumerate(records) if i in indices_to_keep]\n",
    "    print(\"Duplicate records have been removed, keeping one copy of each.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the details from the description of each record\n",
    "data = []\n",
    "\n",
    "# Iterate through records for every pair for NA and HA segments\n",
    "for record1, record2 in zip(records[::2], records[1::2]):\n",
    "    description1 = record1.description.split('|')\n",
    "    description2 = record2.description.split('|')\n",
    "\n",
    "    # Assume the isolate name is the same for both segments\n",
    "    isolate_name1 = description1[0].strip()\n",
    "    isolate_name2 = description2[0].strip()\n",
    "    if isolate_name1 != isolate_name2:\n",
    "        print(f\"Isolate names do not match: {isolate_name1} vs {isolate_name2}\")\n",
    "        raise ValueError(\"Isolate names do not match\")\n",
    "\n",
    "    # Assume the isolate ID is the same for both segments\n",
    "    isolate_id1 = description1[1].strip()\n",
    "    isolate_id2 = description2[1].strip()\n",
    "    if isolate_id1 != isolate_id2:\n",
    "        print(f\"Isolate IDs do not match: {isolate_id1} vs {isolate_id2}\")\n",
    "        raise ValueError(\"Isolate IDs do not match\")\n",
    "\n",
    "    # Assume the flu type is the same for both segments\n",
    "    flu_type1 = description1[2].strip()\n",
    "    flu_type2 = description2[2].strip()\n",
    "    if flu_type1 != flu_type2:\n",
    "        print(f\"Flu types do not match: {flu_type1} vs {flu_type2}\")\n",
    "        raise ValueError(\"Flu types do not match\")\n",
    "\n",
    "    # Assume the lineage is the same for both segments\n",
    "    lineage1 = description1[3].strip()\n",
    "    lineage2 = description2[3].strip()\n",
    "    if lineage1 != lineage2:\n",
    "        print(f\"Lineages do not match: {lineage1} vs {lineage2}\")\n",
    "        raise ValueError(\"Lineages do not match\")\n",
    "\n",
    "    # The segment labels are different for NA and HA segments\n",
    "    segment1 = description1[4].strip()\n",
    "    segment2 = description2[4].strip()  \n",
    "\n",
    "    # Assume the collection date is the same for both segments\n",
    "    collection_date1 = description1[5].strip()\n",
    "    collection_date2 = description2[5].strip()\n",
    "    if collection_date1 != collection_date2:\n",
    "        print(f\"Collection dates do not match: {collection_date1} vs {collection_date2}\")\n",
    "        raise ValueError(\"Collection dates do not match\")\n",
    "\n",
    "    # Assume the clade is the same for both segments. This is important as this will be our label for classification\n",
    "    clade1 = description1[6].strip()\n",
    "    clade2 = description2[6].strip()\n",
    "    if clade1 != clade2:\n",
    "        print(f\"Clades do not match: {clade1} vs {clade2}\")\n",
    "        raise ValueError(\"Clades do not match\")\n",
    "\n",
    "    # The sequences will be different corresopnding to the NA and HA segments\n",
    "    sequence1 = str(record1.seq)\n",
    "    sequence2 = str(record2.seq)\n",
    "    if segment1 == 'HA':\n",
    "        sequence_ha = sequence1\n",
    "        sequence_na = sequence2\n",
    "    else: # segment2 == 'HA'\n",
    "        sequence_ha = sequence2\n",
    "        sequence_na = sequence1\n",
    "    data.append([isolate_name1, isolate_id1, flu_type1, lineage1, sequence_ha, sequence_na, collection_date1, clade1])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Isolate_Name', 'Isolate_ID', 'Flu_Type', 'Lineage', 'HA', 'NA', 'Collection Date', 'Clade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data  \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Type using regular expressions\n",
    "df['Type'] = df['Flu_Type'].astype(str).str.extract(r'(A|B|C)').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract H_Subtype and N_Subtype with updated regex, allowing for one or more digits after H or N.\n",
    "df['H_Subtype'] = df['Flu_Type'].astype(str).str.extract(r'(H\\d+)').fillna('')\n",
    "df['N_Subtype'] = df['Flu_Type'].astype(str).str.extract(r'(N\\d+)').fillna('')\n",
    "print(df['H_Subtype'].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "print(df['N_Subtype'].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data again\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to strings except Collection Date\n",
    "df = df.astype(str)\n",
    "\n",
    "# Convert \"Collection Date\" column to date\n",
    "df[\"Collection Date\"] = pd.to_datetime(df[\"Collection Date\"])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows in training data\n",
    "print(f'df has {df.duplicated().sum()} duplicate rows')\n",
    "display(df[df.duplicated()])\n",
    "# Drop duplicates and check again\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'df has {df.duplicated().sum()} duplicate rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Missing values / NaN / Empty Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and empty strings\n",
    "print(\"NaN values in df:\")\n",
    "print(df.isnull().sum())  # Check for NaN values\n",
    "print(\"\\nEmpty string values in df:\")\n",
    "for col in df.select_dtypes(include=['object']):  # Iterate over columns with string datatype\n",
    "    print(f\"{col}: {(df[col] == '').sum()}\")     # Count empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls or empty strings in Clade, ignore Lineage nulls/empty strings\n",
    "df.replace('', pd.NA, inplace=True)  # Replace empty strings with NaN\n",
    "df.dropna(subset=['Clade'], inplace=True)  # Drop rows where Clade is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and empty strings\n",
    "# NOTE: the previous empty strings that were not removed will now show up as NaN as we replaced empty strings with NaN\n",
    "print(\"NaN values in df:\")\n",
    "print(df.isnull().sum())  # Check for NaN values\n",
    "print(\"\\nEmpty string values in df:\")\n",
    "for col in df.select_dtypes(include=['object']):  # Iterate over columns with string datatype\n",
    "    print(f\"{col}: {(df[col] == '').sum()}\")     # Count empty strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clade Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with \"unassigned\" in 'Clade' from the training data\n",
    "df = df[df['Clade'] != 'unassigned']  # Filter out rows with label \"unassigned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H_Subtype Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['H_Subtype'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N_Subtype Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['N_Subtype'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 Look at sequence length stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_length(row, column):\n",
    "    \"\"\"Calculates the length of the sequence in the specified column.\"\"\"\n",
    "    return len(row[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_sequence_lengths = df.apply(get_sequence_length, axis=1, column=\"HA\")\n",
    "na_sequence_lengths = df.apply(get_sequence_length, axis=1, column=\"NA\")\n",
    "print(\"Sequence lengths in HA columns:\")\n",
    "ha_sequence_lengths.describe()\n",
    "print(\"Sequence lengths in NA columns:\")\n",
    "na_sequence_lengths.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 K-mers and k-mer encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define k-mer length\n",
    "# kmer_length = 12\n",
    "kmer_length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract kmers (can be reused)\n",
    "def get_kmers(sequence, k):\n",
    "  \"\"\"\n",
    "  Extracts all k-mers (subsequences of length k) from a DNA sequence.\n",
    "  \"\"\"\n",
    "  kmers = []\n",
    "  for i in range(len(sequence) - k + 1):\n",
    "    kmer = sequence[i:i+k]\n",
    "    kmers.append(kmer)\n",
    "  return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store kmers for each sequence (identified by row index)\n",
    "kmer_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract k-mers with length kmer_length from each sequence and store them in the dictionary\n",
    "for i, row in df.iterrows():\n",
    "  # Extract kmers from HA sequence (assuming it exists)\n",
    "  ha_kmers = []\n",
    "  if \"HA\" in row:  # Check if \"HA\" column exists\n",
    "    sequence = str(row[\"HA\"])\n",
    "    ha_kmers = get_kmers(sequence, kmer_length)\n",
    "\n",
    "  # Store kmers separately in the dictionary\n",
    "  kmer_dict[i] = {\n",
    "    \"HA\": ha_kmers\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[22, \"HA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index = 22  # Replace with the desired row index\n",
    "kmer_breakdown = kmer_dict[row_index]\n",
    "print(kmer_breakdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 One-Hot Encoding using chunking to optimize memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chunk size (adjust as needed)\n",
    "chunk_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk_dict):\n",
    "    \"\"\"\n",
    "    Processes a chunk of data from the kmer_dict and returns one-hot encoded features.\n",
    "    \"\"\"\n",
    "    chunk_ha_features = []\n",
    "\n",
    "    # Get unique k-mers across all sequences in the chunk\n",
    "    # Only run this code if 'ohe' attribute does not exist. This is to ensure that the one-hot encoder is only fit once.\n",
    "    # So, for the test data, 'ohe' already defined, this code will not run (will not do a fit on a new OHE) and go directly to the transformation step below\n",
    "    if not hasattr(process_chunk, 'ohe'):\n",
    "        all_kmers = set()\n",
    "        for kmer_dict_row in chunk_dict.values():\n",
    "            ha_kmers = kmer_dict_row[\"HA\"]\n",
    "            all_kmers.update(ha_kmers)\n",
    "\n",
    "        # Create one-hot encoder (only fit on the first chunk for consistent categories)\n",
    "        process_chunk.ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        process_chunk.ohe.fit([[kmer] for kmer in list(all_kmers)])  # Fit on unique kmers\n",
    "\n",
    "    # Transform each sequence into a one-hot encoded vector\n",
    "    for kmer_dict_row in chunk_dict.values():\n",
    "        ha_kmers = kmer_dict_row[\"HA\"]\n",
    "        kmer_indices = process_chunk.ohe.transform([[kmer] for kmer in ha_kmers]).sum(axis=0)\n",
    "        chunk_ha_features.append(kmer_indices)\n",
    "\n",
    "    return chunk_ha_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through kmer_dict in chunks\n",
    "ha_features = []\n",
    "for i in range(0, len(kmer_dict), chunk_size):\n",
    "  # Get a chunk of data\n",
    "  chunk_dict = dict(list(kmer_dict.items())[i:i + chunk_size])\n",
    "\n",
    "  # Process features for the chunk\n",
    "  chunk_ha_features = process_chunk(chunk_dict)\n",
    "\n",
    "  # Append features from the chunk\n",
    "  ha_features.extend(chunk_ha_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define X and y and Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "# Convert list of lists to numpy array for X (training data)\n",
    "X = np.array(ha_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder to all unique classes (call only once)\n",
    "le.fit(df['Clade'])\n",
    "\n",
    "for index in df.index:\n",
    "  clade_label = le.transform(np.array([df.loc[index, \"Clade\"]]))[0]\n",
    "  y.append(clade_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Set random_state for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a Random Forest model\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust hyperparameters\n",
    "# model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model with balanced class weights to handle class imbalance\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') \n",
    "model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Predictions\n",
    "print(\"\\n### Model Evaluation on Train/Validation Dataset ###\")\n",
    "\n",
    "# Accuracy: Proportion of correctly predicted samples\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Precision: Ratio of true positives to all predicted positives\n",
    "precision = precision_score(y_test, y_pred, average='weighted') # Weighted average for multi-class\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall: Ratio of true positives to all actual positives\n",
    "recall = recall_score(y_test, y_pred, average='weighted')  # Weighted average for multi-class\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1-score: Harmonic mean of precision and recall\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Weighted average for multi-class\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix with Seaborn\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a new figure for the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create heatmap using seaborn\n",
    "heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\") # Customize heatmap with annotations, format, and colormap\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted Clade\")\n",
    "plt.ylabel(\"True Clade\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Show the confusion matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End timing\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_runtime(total_time):\n",
    "    \"\"\"\n",
    "    Formats a given runtime (in seconds) into a human-readable string, \n",
    "    omitting zero-value components (days, hours, minutes).\n",
    "\n",
    "    Args:\n",
    "        total_time (float): The total runtime in seconds.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string representing the runtime.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert total time in seconds to a timedelta object\n",
    "    td = datetime.timedelta(seconds=total_time)\\\n",
    "    \n",
    "    # Extract days, hours, minutes, and seconds from the timedelta\n",
    "    days = td.days\n",
    "    hours, remainder = divmod(td.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    # Create a list to store non-zero time components and their labels\n",
    "    time_components = []\n",
    "    if days > 0:\n",
    "        time_components.append(f\"{days} days\")\n",
    "    if hours > 0:\n",
    "        time_components.append(f\"{hours} hours\")\n",
    "    if minutes > 0:\n",
    "        time_components.append(f\"{minutes} minutes\")\n",
    "    time_components.append(f\"{seconds:.2f} seconds\")  # Always include seconds\n",
    "\n",
    "    # Join the time components with commas and \"and\"\n",
    "    formatted_time = \", \".join(time_components[:-1])  # Join all but the last\n",
    "    if len(time_components) > 1:\n",
    "        formatted_time += \" and \" + time_components[-1]  # Add \"and\" and the last\n",
    "    else:\n",
    "        formatted_time = time_components[0]  # If only one component, use it directly\n",
    "\n",
    "    return formatted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print total training and validation runtime\n",
    "training_and_validation_time = end_time - start_time\n",
    "print(f\"\\nTotal training and validation runtime: {format_runtime(training_and_validation_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer Importance, how many clades contain this k-mer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Map feature indices back to k-mers\n",
    "kmer_names = process_chunk.ohe.get_feature_names_out()  # Get k-mer names from the encoder\n",
    "\n",
    "feature_importances = pd.DataFrame({'kmer': kmer_names, 'importance': importances})\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# Create an empty list to store clades associated with each k-mer\n",
    "clades_with_kmer = []\n",
    "\n",
    "# Iterate through each k-mer in feature_importances\n",
    "for _, row in feature_importances.iterrows():\n",
    "    kmer = row['kmer']\n",
    "    kmer_index = np.where(kmer_names == kmer)[0][0]  # Get the index of the k-mer\n",
    "\n",
    "    # Find rows in X_train where this k-mer is present (non-zero value)\n",
    "    rows_with_kmer = np.where(X_train[:, kmer_index] > 0)[0]\n",
    "\n",
    "    # Get the corresponding clade labels from y_train\n",
    "    clade_labels = [y_train[i] for i in rows_with_kmer]\n",
    "\n",
    "    # Decode the clade labels and get unique clades\n",
    "    unique_clades = list(set(le.inverse_transform(clade_labels)))\n",
    "\n",
    "    # Append the list of clades to clades_with_kmer\n",
    "    clades_with_kmer.append(unique_clades)\n",
    "\n",
    "# Add a new column 'Clades' to feature_importances\n",
    "feature_importances['Clades'] = clades_with_kmer\n",
    "\n",
    "# Get the total number of unique clades\n",
    "total_clades = len(le.classes_) \n",
    "\n",
    "# Add a new column 'Clade Proportion' to calculate the proportion\n",
    "feature_importances['Clade Proportion'] = feature_importances['Clades'].apply(lambda x: len(x) / total_clades)\n",
    "\n",
    "# # Increase the maximum number of rows and columns to display\n",
    "# pd.set_option('display.max_rows', None)  # Display all rows\n",
    "# pd.set_option('display.max_columns', None)  # Display all columns   \n",
    "\n",
    "# # You can also specifically increase the width of the 'Clades' column\n",
    "# pd.set_option('display.max_colwidth', None)  # No limit on column width\n",
    "\n",
    "total_kmers = len(kmer_names) # Assuming kmer_names contains all unique k-mers\n",
    "\n",
    "# Display the top N most important k-mers\n",
    "N = 20  # You can adjust this to show more or fewer k-mers\n",
    "print(f\"\\nTop {N} (of {total_kmers}) most important k-mers:\")\n",
    "display(feature_importances.head(N))\n",
    "\n",
    "# Print feature_importances to markdown\n",
    "print(feature_importances.head(N).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# # Output everyting to file\n",
    "# feature_importances.to_csv('feature_importances.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP on k-mer importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the SHAP explainer. For tree-based models like Random Forest, use TreeExplainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values for the test set, disabling the additivity check\n",
    "shap_values = explainer.shap_values(X_test, check_additivity=False) # You might want to use a smaller subset of X_test for faster computation\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(shap_values.shape)\n",
    "print(X_test.shape)\n",
    "print(len(process_chunk.ohe.get_feature_names_out()))\n",
    "\n",
    "# Visualize the first prediction's explanation for the first class (index 0)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0,:,0], feature_names=process_chunk.ohe.get_feature_names_out())\n",
    "\n",
    "# Summarize the effects of all the features for all classes\n",
    "shap.summary_plot(shap_values, X_test, feature_names=process_chunk.ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a timestamp\n",
    "def get_timestamp():\n",
    "  now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "  return now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "timestamp = get_timestamp()\n",
    "model_data = {'model': model, 'label_encoder': le, 'one_hot_encoder': process_chunk.ohe} # Save the model, labelencoder, and OHE together\n",
    "model_filename = f\"model_learn-flu-train_{timestamp}.joblib\"\n",
    "joblib.dump(model_data, model_filename)\n",
    "print(f\"Trained Model, LabelEncoder, and OneHotEncoder and saved to: {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-flu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
